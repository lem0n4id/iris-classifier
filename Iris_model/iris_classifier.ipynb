{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gshz-dU0Fp1"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JFCLyFW0Lit"
      },
      "source": [
        "# load dataset\n",
        "iris_dataset = load_iris()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl3AjdSvkpCE"
      },
      "source": [
        "# 75% of data would be train data - default\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_dataset['data'], iris_dataset['target'], random_state=42) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4ttRjAI5V8o",
        "outputId": "15bd09ed-cc5a-4080-e8e6-655355456104"
      },
      "source": [
        "# Initailize and fit the model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaEtkjTnRch7"
      },
      "source": [
        "# Saving the model\n",
        "import pickle\n",
        "f = open('my_model.pickle', 'wb')\n",
        "pickle.dump(model, f)\n",
        "f.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQIR3wxKOW19"
      },
      "source": [
        "# Accuracy score\n",
        "Here you csn see that we are getting 100% accuracy on the test data. \n",
        "\n",
        "Futher, We can verify this if this is really true or not by doing \n",
        "```\n",
        "y_test == predicted_y \n",
        "```\n",
        "which returns true for all the datapoints in the test data\n",
        "\n",
        "## Reason\n",
        "\n",
        "This is probably due to the small dataset we have. Iris dataset we have right now only has 150 datapoints \n",
        "\n",
        "which is not ideal for Machine Learning models in real life applications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zzjv3gSks7o"
      },
      "source": [
        "from sklearn.metrics import accuracy_score #, cross_validate\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "predicted_y = model.predict(X_test)\n",
        "\n",
        "# Calculating accuracy score \n",
        "accuracy_score = accuracy_score(y_test, predicted_y) \n",
        "print(f'accuracy score: {accuracy_score*100}%')\n",
        "\n",
        "s = model.score(X_test, y_test)\n",
        "print(f'accuracy score: {s*100}%')\n",
        "\n",
        "# Verifying the accuracy score\n",
        "print(y_test==predicted_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H51LoGpHPqPJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}